#!/bin/bash

XDG_DATA_HOME=${XDG_DATA_HOME:-$HOME/.local/share}
XDG_CACHE_HOME=${XDG_CACHE_HOME:-$HOME/.cache}
XDG_CONFIG_HOME=${XDG_CONFIG_HOME:-$HOME/.config}

source "$XDG_DATA_HOME/work-environment/functions.sh"

if [[ -n $1 ]]
then
  export CLUSTERID=$1
fi

if [[ -z "$CLUSTERID" ]]
then
  echo "Usage: source cluster <clusterid>" > /dev/stderr
else
  # Unset any previous cluster variables.
  unset KUBECONFIG
  unset OCM_CONFIG
  unset OCM_CLUSTERID
  unset AWS_PROFILE
  unset AWS_DEFAULT_REGION

  if [[ "$CLUSTERID" == "none" ]]
  then
    # Special name to reset the environment.
    unset CLUSTERID
  else
    CACHE_FILE=$(cluster_cache_file_exact $CLUSTERID)
    if [[ -f $CACHE_FILE ]]
    then
      CLUSTERID=$(cluster_from_cache_file $CACHE_FILE)
      case $CLUSTERID in
        v3:*)
          VERSION=v3
          CLUSTERID=${CLUSTERID:3}  # Trim off v3:
          export AWS_PROFILE=$(get-cluster-var $CLUSTERID oo_account)
          export AWS_DEFAULT_REGION=$(get-cluster-var $CLUSTERID oo_sublocation)
          cluster-context
          ;;
        ocm:*)
          VERSION=ocm
          CLUSTERID=${CLUSTERID:4}  # Trim off ocm:
          export KUBECONFIG="${CACHE_FILE/$XDG_CACHE_HOME/$XDG_CONFIG_HOME}"
          OCM_CONFIG_DIR=$(dirname $(dirname $KUBECONFIG))
          mkdir -p "$OCM_CONFIG_DIR/clusters"
          export OCM_CONFIG="$OCM_CONFIG_DIR/config"
          export OCM_CLUSTERID=$(get-cluster-var $CLUSTERID id)
          export AWS_DEFAULT_REGION=$(get-cluster-var $CLUSTERID region.id)
          if [[ ! -e $KUBECONFIG ]]
          then
            case $(basename $OCM_CONFIG_DIR) in
              integration|staging)
                # Requires ocm role SREPDeveloper
                ocm get /api/clusters_mgmt/v1/clusters/$OCM_CLUSTERID/credentials | jq -r .kubeconfig > $KUBECONFIG
                ;;
              production)
                touch $KUBECONFIG
                ;;
            esac
          fi
          cluster-context
          ;;
        *)
          echo "Panic! Unrecognized cache file $CACHE_FILE" > /dev/stderr
          ;;
      esac
    fi
  fi
fi

TMUX_CLUSTER_FILE=$(tmux-cluster-file)
if [[ -n "$TMUX_CLUSTER_FILE" ]]
then
  if [[ -n "$VERSION" ]] && [[ -n "$CLUSTERID" ]]
  then
    if [[ -d $(dirname $TMUX_CLUSTER_FILE) ]]
    then
        echo "export CLUSTERID=$CLUSTERID" > $TMUX_CLUSTER_FILE
        echo "export AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION" >> $TMUX_CLUSTER_FILE
        if [[ -n "$AWS_PROFILE" ]]
        then
            echo "export AWS_PROFILE=$AWS_PROFILE" >> $TMUX_CLUSTER_FILE
        fi
        if [[ -n "$KUBECONFIG" ]]
        then
            echo "export KUBECONFIG=$KUBECONFIG" >> $TMUX_CLUSTER_FILE
        fi
        if [[ -n "$OCM_CLUSTERID" ]]
        then
            echo "export OCM_CLUSTERID=$OCM_CLUSTERID" >> $TMUX_CLUSTER_FILE
        fi
        if [[ -n "$OCM_CONFIG" ]]
        then
            echo "export OCM_CONFIG=$OCM_CONFIG" >> $TMUX_CLUSTER_FILE
        fi
    fi
    tmux rename-window "$VERSION:$CLUSTERID"
  else
    rm --force $TMUX_CLUSTER_FILE
    tmux rename-window ""
  fi
fi

unset VERSION
